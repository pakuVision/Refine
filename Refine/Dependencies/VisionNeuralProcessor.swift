//
//  AI.swift
//  Refine
//
//  Created by boardguy.vision on 2026/02/12.
//

//
//  VisionNeuralProcessor.swift
//  Refine
//

import CoreImage
import Vision
import UIKit
import ImageIO

actor VisionNeuralProcessor {
    
    private let context = CIContext(options: [
        .workingColorSpace: CGColorSpace(name: CGColorSpace.displayP3)!,
        .useSoftwareRenderer: false,
        .cacheIntermediates: false
    ])
    
    func process(_ imageData: Data) async throws -> Data {
        // 1. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        guard let imageSource = CGImageSourceCreateWithData(imageData as CFData, nil),
              let metadata = CGImageSourceCopyPropertiesAtIndex(imageSource, 0, nil) as? [CFString: Any] else {
            throw ProcessingError.invalidImageData
        }
        
        // 2. CIImage ë¡œë“œ
        guard let ciImage = CIImage(data: imageData)?.oriented(forExifOrientation: extractExifOrientation(from: metadata)) else {
            throw ProcessingError.invalidImageData
        }
        
        print("ðŸ§  Neural Engine ì²˜ë¦¬ ì‹œìž‘: \(Int(ciImage.extent.width))x\(Int(ciImage.extent.height))")
        
        // 3. Neural Engineìœ¼ë¡œ í”¼ì‚¬ì²´ ê°ì§€
        let subjectMask = try await detectSubject(ciImage)
        
        if let mask = subjectMask {
            print("âœ… í”¼ì‚¬ì²´ ê°ì§€ ì„±ê³µ - ì„ íƒì  ì²˜ë¦¬")
            // í”¼ì‚¬ì²´ê°€ ìžˆìœ¼ë©´ ì„ íƒì  í–¥ìƒ
            let enhanced = enhanceWithSubjectMask(ciImage, mask: mask)
            return try await saveAsHEIFWithMetadata(enhanced, originalMetadata: metadata)
        } else {
            print("âš ï¸ í”¼ì‚¬ì²´ ì—†ìŒ - ì „ì²´ í–¥ìƒ")
            // í”¼ì‚¬ì²´ ì—†ìœ¼ë©´ ì „ì²´ ì•½í•˜ê²Œ í–¥ìƒ
            let enhanced = enhanceGlobal(ciImage)
            return try await saveAsHEIFWithMetadata(enhanced, originalMetadata: metadata)
        }
    }
    
    // MARK: - Subject Detection (Neural Engine)
    
    private func detectSubject(_ image: CIImage) async throws -> CIImage? {
        guard let cgImage = context.createCGImage(image, from: image.extent) else {
            throw ProcessingError.renderFailed
        }
        
        return try await withCheckedThrowingContinuation { continuation in
            // âœ… VNGeneratePersonSegmentationRequest - Neural Engine ì‚¬ìš©
            let request = VNGeneratePersonSegmentationRequest { request, error in
                if let error = error {
                    print("âš ï¸ í”¼ì‚¬ì²´ ê°ì§€ ì‹¤íŒ¨: \(error.localizedDescription)")
                    continuation.resume(returning: nil)
                    return
                }
                
                guard let observation = request.results?.first as? VNPixelBufferObservation else {
                    print("âš ï¸ í”¼ì‚¬ì²´ ì—†ìŒ")
                    continuation.resume(returning: nil)
                    return
                }
                
                // CVPixelBuffer â†’ CIImage
                let maskImage = CIImage(cvPixelBuffer: observation.pixelBuffer)
                print("âœ… í”¼ì‚¬ì²´ ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ")
                continuation.resume(returning: maskImage)
            }
            
            // âœ… Neural Engine ì‚¬ìš© ì„¤ì •
            request.qualityLevel = .accurate  // Neural Engine ìµœëŒ€ í™œìš©
            
            let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
            
            do {
                try handler.perform([request])
            } catch {
                print("âš ï¸ Vision ì—ëŸ¬: \(error)")
                continuation.resume(returning: nil)
            }
        }
    }
    
    // MARK: - Enhance with Subject Mask
    
    private func enhanceWithSubjectMask(_ image: CIImage, mask: CIImage) -> CIImage {
        // ë§ˆìŠ¤í¬ë¥¼ ì´ë¯¸ì§€ í¬ê¸°ì— ë§žì¶¤
        let scaledMask = mask.transformed(by: CGAffineTransform(
            scaleX: image.extent.width / mask.extent.width,
            y: image.extent.height / mask.extent.height
        ))
        
        // 1. í”¼ì‚¬ì²´ ì˜ì—­ ì¶”ì¶œ
        let subject = extractSubject(image, mask: scaledMask)
        
        // 2. ë°°ê²½ ì˜ì—­ ì¶”ì¶œ
        let background = extractBackground(image, mask: scaledMask)
        
        // 3. í”¼ì‚¬ì²´: ê°•í•˜ê²Œ ìƒ¤í”„ë‹
        let enhancedSubject = sharpenSubject(subject)
        
        // 4. ë°°ê²½: ì•½í•˜ê²Œ ë…¸ì´ì¦ˆ ì œê±°
        let cleanBackground = cleanBackground(background)
        
        // 5. í•©ì„±
        return enhancedSubject.composited(over: cleanBackground)
    }
    
    // MARK: - Extract Subject
    
    private func extractSubject(_ image: CIImage, mask: CIImage) -> CIImage {
        // ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•´ í”¼ì‚¬ì²´ë§Œ ì¶”ì¶œ
        return image.applyingFilter("CIBlendWithMask", parameters: [
            kCIInputMaskImageKey: mask
        ])
    }
    
    // MARK: - Extract Background
    
    private func extractBackground(_ image: CIImage, mask: CIImage) -> CIImage {
        // ë§ˆìŠ¤í¬ ë°˜ì „ (í”¼ì‚¬ì²´ ì œì™¸)
        guard let invertedMask = CIFilter(name: "CIColorInvert", parameters: [
            kCIInputImageKey: mask
        ])?.outputImage else {
            return image
        }
        
        return image.applyingFilter("CIBlendWithMask", parameters: [
            kCIInputMaskImageKey: invertedMask
        ])
    }
    
    // MARK: - Sharpen Subject
    
    private func sharpenSubject(_ subject: CIImage) -> CIImage {
        var result = subject
        
        // 1. Unsharp Mask (ê°•í•˜ê²Œ)
        if let filter = CIFilter(name: "CIUnsharpMask") {
            filter.setValue(result, forKey: kCIInputImageKey)
            filter.setValue(1.5, forKey: kCIInputRadiusKey)
            filter.setValue(0.8, forKey: kCIInputIntensityKey)  // í”¼ì‚¬ì²´ëŠ” ê°•í•˜ê²Œ
            result = filter.outputImage ?? result
        }
        
        // 2. Sharpen Luminance
        if let filter = CIFilter(name: "CISharpenLuminance") {
            filter.setValue(result, forKey: kCIInputImageKey)
            filter.setValue(0.5, forKey: kCIInputSharpnessKey)
            result = filter.outputImage ?? result
        }
        
        // 3. ëŒ€ë¹„ ì•½ê°„ ì¦ê°€
        if let filter = CIFilter(name: "CIColorControls") {
            filter.setValue(result, forKey: kCIInputImageKey)
            filter.setValue(1.1, forKey: kCIInputContrastKey)
            result = filter.outputImage ?? result
        }
        
        return result
    }
    
    // MARK: - Clean Background
    
    private func cleanBackground(_ background: CIImage) -> CIImage {
        var result = background
        
        // ë°°ê²½ì€ ì•½í•˜ê²Œ ë…¸ì´ì¦ˆë§Œ ì œê±°
        if let filter = CIFilter(name: "CINoiseReduction") {
            filter.setValue(result, forKey: kCIInputImageKey)
            filter.setValue(0.01, forKey: "inputNoiseLevel")  // ì•½í•˜ê²Œ
            filter.setValue(0.60, forKey: "inputSharpness")
            result = filter.outputImage ?? result
        }
        
        return result
    }
    
    // MARK: - Enhance Global (í”¼ì‚¬ì²´ ì—†ì„ ë•Œ)
    
    private func enhanceGlobal(_ image: CIImage) -> CIImage {
        var result = image
        
        // ì „ì²´ì ìœ¼ë¡œ ë§¤ìš° ì•½í•˜ê²Œë§Œ
        if let filter = CIFilter(name: "CISharpenLuminance") {
            filter.setValue(result, forKey: kCIInputImageKey)
            filter.setValue(0.2, forKey: kCIInputSharpnessKey)  // ì•„ì£¼ ì•½í•˜ê²Œ
            result = filter.outputImage ?? result
        }
        
        return result
    }
    
    // MARK: - Helpers
    
    private func extractExifOrientation(from metadata: [CFString: Any]) -> Int32 {
        if let orientation = metadata[kCGImagePropertyOrientation] as? Int32 {
            return orientation
        }
        return 1
    }
    
    private func saveAsHEIFWithMetadata(_ image: CIImage, originalMetadata: [CFString: Any]) async throws -> Data {
        let colorSpace = CGColorSpace(name: CGColorSpace.displayP3) ?? CGColorSpaceCreateDeviceRGB()
        
        guard let cgImage = context.createCGImage(
            image,
            from: image.extent,
            format: .RGBA16,
            colorSpace: colorSpace
        ) else {
            // fallback to RGBA8
            guard let cgImage8 = context.createCGImage(
                image,
                from: image.extent,
                format: .RGBA8,
                colorSpace: colorSpace
            ) else {
                throw ProcessingError.renderFailed
            }
            return try saveWithCGImage(cgImage8, metadata: originalMetadata)
        }
        
        return try saveWithCGImage(cgImage, metadata: originalMetadata)
    }
    
    private func saveWithCGImage(_ cgImage: CGImage, metadata: [CFString: Any]) throws -> Data {
        let mutableData = NSMutableData()
        
        guard let destination = CGImageDestinationCreateWithData(
            mutableData,
            "public.heic" as CFString,
            1,
            nil
        ) else {
            throw ProcessingError.exportFailed
        }
        
        var properties = metadata
        properties[kCGImagePropertyOrientation] = 1
        properties[kCGImageDestinationLossyCompressionQuality] = 1.0
        
        CGImageDestinationAddImage(destination, cgImage, properties as CFDictionary)
        
        guard CGImageDestinationFinalize(destination) else {
            throw ProcessingError.exportFailed
        }
        
        print("âœ… Neural Engine ì²˜ë¦¬ ì™„ë£Œ: \(mutableData.count) bytes")
        return mutableData as Data
    }
}
